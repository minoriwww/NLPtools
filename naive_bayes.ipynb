{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[使用sklearn自带的贝叶斯分类器进行文本分类和参数调优](http://www.jianshu.com/p/0bf2eb488afa)\n",
    "[使用sklearn + jieba中文分词构建文本分类器](http://www.tuicool.com/articles/vYnIve)\n",
    "[NLP系列(4)_朴素贝叶斯实战与进阶](http://www.kancloud.cn/digest/machine-learning-dm/125822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*- \n",
    "import sys\n",
    "import numpy\n",
    "import jieba\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import codecs\n",
    "import itertools, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "f = open('data.txt')         \n",
    "# sourceInLines = f.readlines()  \n",
    "#按行读出文件内容\n",
    "train_data = []      \n",
    "line = \"\"                             \n",
    "for lines in f:\n",
    "    \n",
    "    if lines.strip().decode('utf-8') == \"----------\":\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        train_data.append(line)\n",
    "        line = \"\"\n",
    "        \n",
    "    else:\n",
    "        line += lines.strip().decode('utf-8')\n",
    "        \n",
    "# print ''.join(new)\n",
    "print len(train_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "f = open('target.txt')         \n",
    "# sourceInLines = f.readlines()  \n",
    "#按行读出文件内容\n",
    "train_target = []      \n",
    "line = \"\"                             \n",
    "for lines in f:\n",
    "\n",
    "    train_target.append(line)\n",
    "        \n",
    "# print ''.join(new)\n",
    "print len(train_target)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comma_tokenizer = lambda x: jieba.cut(x, cut_all=True)\n",
    "\n",
    "\n",
    "def vectorize(train_words, test_words):\n",
    "    v = HashingVectorizer(tokenizer=comma_tokenizer, n_features=30000, non_negative=True)\n",
    "    train_data = v.fit_transform(train_words)\n",
    "    test_data = v.fit_transform(test_words)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def evaluate(actual, pred):\n",
    "    m_precision = metrics.precision_score(actual, pred)\n",
    "    m_recall = metrics.recall_score(actual, pred)\n",
    "    print 'precision:{0:.3f}'.format(m_precision)\n",
    "    print 'recall:{0:0.3f}'.format(m_recall)\n",
    "\n",
    "\n",
    "def train_clf(train_data, train_tags):\n",
    "    clf = MultinomialNB(alpha=0.01)\n",
    "    clf.fit(train_data, numpy.asarray(train_tags))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '']\n",
      "126\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "    # 训练集和测试集的比例为7:3\n",
    "filesize = int(0.1 * len(train_target))\n",
    "train_words = train_data[:filesize]\n",
    "train_tags = train_target[:filesize]\n",
    "test_words = train_data[filesize:] \n",
    "test_tags = train_target[filesize:] \n",
    "\n",
    "\n",
    "\n",
    "# train_words, train_tags, test_words, test_tags = input_data(train_file, test_file)\n",
    "train_data, test_data = vectorize(train_words, test_words)\n",
    "# print train_data, test_data\n",
    "clf = train_clf(train_data, train_tags)\n",
    "pred = clf.predict(test_data)\n",
    "print pred\n",
    "length = len(test_tags)\n",
    "test_tags = numpy.array(test_tags)\n",
    "# print test_tags.tolist()\n",
    "# print pred.tolist()\n",
    "right_num = (test_tags == pred).sum()\n",
    "print(right_num)\n",
    "print length\n",
    "# print test_tags\n",
    "# evaluate(numpy.asarray(test_tags), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
